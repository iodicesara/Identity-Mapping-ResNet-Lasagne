{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week02_NetworkTraining.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iodicesara/Identity-Mapping-ResNet-Lasagne/blob/master/week02_NetworkTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "91E7ozNTWvS9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Network Training\n",
        "\n",
        "In this tutorial we will introduce different topics related to the traning phase of deep neural networks,  including data augmentations, optimization/regularization techniques, weight initializations, loss function, hyper parameters tuning and final, some metrics to evaluate performances of the model."
      ]
    },
    {
      "metadata": {
        "id": "hVa-ZTYsXhNT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preliminary\n",
        "\n",
        "We will load MNIST as in last weeks tutorial, and we will use it to classify digits and introduce the topics covered in this tutorial."
      ]
    },
    {
      "metadata": {
        "id": "2aGBJBVmXd8b",
        "colab_type": "code",
        "outputId": "bd1b7006-bac8-436e-95ea-a579de310aa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(123)  # for reproducibility\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.utils import np_utils\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "\n",
        "batch_size=128\n",
        "num_classes=10\n",
        "epoch=20\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(y_train.shape[0],'train samples')\n",
        "print(x_train.shape[0],'train samples')\n",
        "\n",
        "print(x_test.shape[0],'test samples')\n",
        "print(x_test.shape[0],'test samples')\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
        "\n",
        "x_train= x_train.astype('float32')\n",
        "x_test= x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "y_train=to_categorical(y_train,num_classes)\n",
        "y_test=to_categorical(y_test,num_classes)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# con\n",
        "\n",
        "# Load simple model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 'train samples')\n",
            "(60000, 'train samples')\n",
            "(10000, 'test samples')\n",
            "(10000, 'test samples')\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_33 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mRx68ymWLCT7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Optimizers\n",
        "\n",
        "\n",
        "The choice of the optimizer can affect both the final performance and the speed of convergence. While some methods are more prone to get stuck in local minima,  others converge faster.  A nice visualization of this is the following animation:\n",
        "\n",
        "![](http://ruder.io/content/images/2016/09/saddle_point_evaluation_optimizers.gif)\n",
        "\n",
        "If you want to know more technical details of different optimizers, plese refer to [Sebastian Ruder's blog](http://ruder.io/optimizing-gradient-descent/).\n",
        "\n",
        "Here we will introduce how to use different optimizers in Keras. \n",
        "\n",
        "As we have previusly seen, the compile method requires two arguments in string format: a loss function and a optimizer. For example, we define as parameters adam and categorical crossentropy, respectively. \n",
        "\n",
        "As a rule of thumb, Adam is usually easier to tune due to the adaptive learning rate, whereas SGD with momentum has been shown to reach better results when tuned correctly.\n",
        "\n",
        "As exercise, try different optimizers - to know how to specify it please consult the official documentation [Optimizers in Keras](https://keras.io/optimizers/) - and finally, report below in the table the training and validation losses you achieve.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "iwvy89V2hd7i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "083f92e0-eb41-44f1-9ada-d83288164b67"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "import tabulate\n",
        "table = [[\"Optimizer\",\"loss\",\"val_loss\",\"hyper-parameters\"],\n",
        "         [\"Adam\",\"-\",\"-\",\"-\"],\n",
        "         [\"Sgd\",\"-\",\"-\",\"lr=0.01, momentum=0.0, decay=0.0\"],\n",
        "         [\"RMSprop\",\"-\" ,\"-\",\"lr=0.001, rho=0.9, epsilon=None, decay=0.0\"],\n",
        "         [\"Adagrad\",\"-\",\"-\",\"-\"],\n",
        "         [\"Adadelta\",\"-\",\"-\",\"-\"],\n",
        "         [\"Adam\",\"-\",\"-\",\"-\"]]\n",
        "display(HTML(tabulate.tabulate(table, tablefmt='html')))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table>\n",
              "<tbody>\n",
              "<tr><td>Optimizer</td><td>loss</td><td>val_loss</td><td>hyper-parameters                          </td></tr>\n",
              "<tr><td>Adam     </td><td>-   </td><td>-       </td><td>-                                         </td></tr>\n",
              "<tr><td>Sgd      </td><td>-   </td><td>-       </td><td>lr=0.01, momentum=0.0, decay=0.0          </td></tr>\n",
              "<tr><td>RMSprop  </td><td>-   </td><td>-       </td><td>lr=0.001, rho=0.9, epsilon=None, decay=0.0</td></tr>\n",
              "<tr><td>Adagrad  </td><td>-   </td><td>-       </td><td>-                                         </td></tr>\n",
              "<tr><td>Adadelta </td><td>-   </td><td>-       </td><td>-                                         </td></tr>\n",
              "<tr><td>Adam     </td><td>-   </td><td>-       </td><td>-                                         </td></tr>\n",
              "</tbody>\n",
              "</table>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9od5lUWMWu5X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3451
        },
        "outputId": "2621df0f-2b17-4879-f33a-8581833794ac"
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy')\n",
        "model.fit(x_train,y_train,batch_size=100,epochs=100,verbose=1,validation_data=(x_test,y_test))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.2101 - val_loss: 0.1029\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0783 - val_loss: 0.0889\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0506 - val_loss: 0.0628\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0342 - val_loss: 0.0688\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0297 - val_loss: 0.0710\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0217 - val_loss: 0.0782\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0192 - val_loss: 0.0665\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0166 - val_loss: 0.0814\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0172 - val_loss: 0.0943\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0147 - val_loss: 0.0850\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0123 - val_loss: 0.0869\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0101 - val_loss: 0.0893\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0140 - val_loss: 0.0781\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0113 - val_loss: 0.0765\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0085 - val_loss: 0.0816\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0077 - val_loss: 0.1079\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0122 - val_loss: 0.1105\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0088 - val_loss: 0.0919\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0065 - val_loss: 0.0970\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0075 - val_loss: 0.1035\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0101 - val_loss: 0.1042\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0067 - val_loss: 0.0997\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0066 - val_loss: 0.1006\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0084 - val_loss: 0.0835\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0031 - val_loss: 0.0928\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0112 - val_loss: 0.1326\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0071 - val_loss: 0.1083\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0051 - val_loss: 0.1011\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0047 - val_loss: 0.1002\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0068 - val_loss: 0.1021\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0114 - val_loss: 0.0969\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0040 - val_loss: 0.1154\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0054 - val_loss: 0.1082\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0061 - val_loss: 0.0986\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0061 - val_loss: 0.1090\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0051 - val_loss: 0.1115\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0030 - val_loss: 0.1227\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0088 - val_loss: 0.1375\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0066 - val_loss: 0.1255\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0034 - val_loss: 0.1172\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0063 - val_loss: 0.1207\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0061 - val_loss: 0.1319\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0060 - val_loss: 0.1108\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0044 - val_loss: 0.1243\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0060 - val_loss: 0.1144\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0040 - val_loss: 0.1142\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0029 - val_loss: 0.1134\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0076 - val_loss: 0.1334\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0073 - val_loss: 0.1000\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0051 - val_loss: 0.1138\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0028 - val_loss: 0.1232\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0042 - val_loss: 0.1253\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0026 - val_loss: 0.1329\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0061 - val_loss: 0.1351\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0066 - val_loss: 0.1137\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0049 - val_loss: 0.1242\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0033 - val_loss: 0.1467\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0039 - val_loss: 0.1433\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0045 - val_loss: 0.1301\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0067 - val_loss: 0.1636\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0084 - val_loss: 0.1415\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.0058 - val_loss: 0.1389\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.0034 - val_loss: 0.1232\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0013 - val_loss: 0.1292\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0053 - val_loss: 0.1389\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0063 - val_loss: 0.1432\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0068 - val_loss: 0.1484\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0040 - val_loss: 0.1467\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0036 - val_loss: 0.1423\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0055 - val_loss: 0.1466\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0063 - val_loss: 0.1518\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0061 - val_loss: 0.1527\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0020 - val_loss: 0.1258\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0028 - val_loss: 0.1320\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0026 - val_loss: 0.1436\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0061 - val_loss: 0.1525\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0058 - val_loss: 0.1362\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0032 - val_loss: 0.1401\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0014 - val_loss: 0.1376\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.0061 - val_loss: 0.1567\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0077 - val_loss: 0.1576\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0026 - val_loss: 0.1274\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0043 - val_loss: 0.1314\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0061 - val_loss: 0.1467\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0032 - val_loss: 0.1371\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0062 - val_loss: 0.1578\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0054 - val_loss: 0.1505\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0040 - val_loss: 0.1385\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0043 - val_loss: 0.1401\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0063 - val_loss: 0.1640\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0050 - val_loss: 0.1525\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0043 - val_loss: 0.1580\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0022 - val_loss: 0.1507\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0052 - val_loss: 0.1421\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0034 - val_loss: 0.1667\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0031 - val_loss: 0.1659\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0015 - val_loss: 0.1553\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0021 - val_loss: 0.1600\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0041 - val_loss: 0.1850\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0112 - val_loss: 0.1780\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d3e34bcd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "8zTr0dB7LjUx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Backpropagation\n",
        "EXPLAIN, AND SHOW Keras example of implementation\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "-yDSecajTyc6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Initializers\n",
        "\n",
        "Different weights initializations may lead to different minimia reached. They are usally initialized at random, however there are several algorithms that can be used. "
      ]
    },
    {
      "metadata": {
        "id": "A6lzySByXcMB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1-8ittW2L1DI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Losses\n",
        "\n",
        "### Classification\n",
        "\n",
        "For classification problems, the standard loss used is the cross-entropy loss, which is defined as:\n",
        "\n",
        "### Regression\n",
        "For regression problems, it is quite standard to use Mean Squared Error or Mean Absolute Error, depending on the problem."
      ]
    },
    {
      "metadata": {
        "id": "F-VrqhSbWJ9t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Regularizations"
      ]
    },
    {
      "metadata": {
        "id": "NuF3Y5DoKylT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## HyperParameters Tuning\n",
        "\n",
        "There are several parameters in the training process that can be modified. One of the most important is the training rate, which controls the update step performed during the backpropagation."
      ]
    },
    {
      "metadata": {
        "id": "xm0oVnMQWLZt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data augmentation\n",
        "Data augmentation techniques such as rotation, color jittering, scale or cropping are usually applied in deep learning pipelines. We take an input image, apply a transformation to it, and then use it for training.\n",
        "\n",
        "Keras includes a preprocessing module, with all [these transformations](https://keras.io/preprocessing/image/) implemented. The preprocessing module can be imported by doing\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "n4glvOHvh8qy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2vftBzsolQcL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then we need to fit it to the input data, and use `flow` to apply the transformations to the input data."
      ]
    },
    {
      "metadata": {
        "id": "OoJYjjapiISI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will now visualize some of the transformations available to use.\n",
        "\n",
        "First we plot some image without any transformation applied for comparison."
      ]
    },
    {
      "metadata": {
        "id": "MyoZHyOTheyU",
        "colab_type": "code",
        "outputId": "18d623fd-4366-429c-fdbd-6c410d06bcab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, 3):\n",
        "\tplt.subplot(130 + 1 + i)\n",
        "\tplt.imshow(X_train[i, 0], cmap=plt.get_cmap('gray'))\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAACkCAYAAADWkiTuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIhIMg6+REREkv0fTfCNI6R7i4QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f12748a4e50>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "eFXEC5EejxWG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Rotation\n",
        "A standard transformation is to rotate the image. We can do so by initializing ImageDataGenerator with `rotation_range=rot_val`."
      ]
    },
    {
      "metadata": {
        "id": "hjgfZ1z3j46X",
        "colab_type": "code",
        "outputId": "e4b2cb3f-1466-455d-d3da-da9f57102e3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "cell_type": "code",
      "source": [
        "# We first define the transformation we want to apply\n",
        "augmentation_gen = ImageDataGenerator(rotation_range=90, data_format = 'channels_first')\n",
        "# We then apply the transformation\n",
        "augmentation_gen.fit(X_train)\n",
        "for X_batch, y_batch in augmentation_gen.flow(X_train, y_train, batch_size=3):\n",
        "\tfor i in range(0, 3):\n",
        "\t\tplt.subplot(130 + 1 + i)\n",
        "\t\tplt.imshow(X_batch[i, 0].reshape(28, 28), cmap=plt.get_cmap('gray'))\n",
        "\t# show the plot\n",
        "\tplt.show()\n",
        "\tbreak\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAACkCAYAAADWkiTuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f12772a97d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Schj43v4ioTY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cropping\n",
        "\n",
        "One of the standard transformations we can apply is cropping. By cropping, we take a smaller part of the image. Some pipelines do center cropping and some other random cropping, among other variations. However, this is not implemented in Keras, so we need to use a custom transformation:"
      ]
    },
    {
      "metadata": {
        "id": "dbzq69FfjLd9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "njqA6ve8WHB1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Performance metrics\n",
        "\n",
        "[Available metrics in Keras](https://keras.io/metrics/)\n",
        "\n",
        "We need some way to evaluate the performance of the model. We do so by using some evaluation metric. Some of the standard evaluation metrics are mean squared error (MSE) and mean absolute error (MAE) for regression problems, or binary or categorical accuracy for classification problems."
      ]
    },
    {
      "metadata": {
        "id": "BPk96eQomRwQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Custom metrics\n",
        "\n",
        "There are cases where we want to use a non-standard metric for evaluating our models. To"
      ]
    },
    {
      "metadata": {
        "id": "D1hsnv_yWfD1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Monitoring Training\n",
        "\n",
        "Tensorboard or similars?"
      ]
    }
  ]
}